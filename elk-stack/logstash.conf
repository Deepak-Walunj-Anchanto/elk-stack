# Logstash configuration for PT (Parcel Tracking)
# 
# Log format from Django: LEVEL|LOGGER_NAME|TIMESTAMP|MESSAGE
# 
# =============================================================================
# FIELDS PRODUCED
# =============================================================================
#   - service: "pt" (from filebeat)
#   - stream: High-level category
#       - django: Django framework (django.request, django.db.backends)
#       - server: Web server (werkzeug)
#       - system: Python internals (asyncio, PIL, root)
#       - aws: AWS SDK (boto, boto3, botocore, s3transfer)
#       - network: HTTP clients (urllib3)
#       - app: Application code (66 loggers from apps.*)
#   - app_module: (only when stream=app) Specific module category
#       - auth, parcels, tenant, notification, reports, etc.
#   - logger_name: Actual logger (apps.parcels.views, django.request, etc.)
#   - log_level: DEBUG, INFO, WARNING, ERROR, CRITICAL
#   - log_message: The actual log message
#
# =============================================================================
# KIBANA QUERIES
# =============================================================================
#   - All framework logs: stream: django OR stream: server OR stream: system
#   - All app logs: stream: app
#   - Specific app module: stream: app AND app_module: auth
#   - Specific logger: logger_name: apps.parcels.views
#   - All errors in auth: stream: app AND app_module: auth AND log_level: ERROR
#
# =============================================================================

input {
  beats {
    port => 5044
  }
}

filter {
  # Only process PT logs
  if [service] == "pt" {
    
    # Parse the log message format: LEVEL|LOGGER_NAME|TIMESTAMP|MESSAGE
    grok {
      match => {
        "message" => [
          "^%{WORD:log_level}\|%{DATA:logger_name}\|%{TIMESTAMP_ISO8601:log_timestamp}\.%{INT:log_ms}\|%{GREEDYDATA:log_message}$",
          "^%{WORD:log_level}\|%{DATA:logger_name}\|%{TIMESTAMP_ISO8601:log_timestamp}\|%{GREEDYDATA:log_message}$"
        ]
      }
      tag_on_failure => ["_grokparsefailure_pt"]
    }

    # Categorize logger_name into stream (and app_module for app stream)
    if [logger_name] {
      
      # ===== FRAMEWORK STREAMS =====
      
      # Django stream - Django framework internals
      if [logger_name] =~ /^django\./ {
        mutate { add_field => { "stream" => "django" } }
      }
      # Server stream - Web server (werkzeug)
      else if [logger_name] == "werkzeug" {
        mutate { add_field => { "stream" => "server" } }
      }
      # AWS stream - AWS SDK libraries
      else if [logger_name] =~ /^boto/ or [logger_name] == "s3transfer" {
        mutate { add_field => { "stream" => "aws" } }
      }
      # Network stream - HTTP clients
      else if [logger_name] == "urllib3" {
        mutate { add_field => { "stream" => "network" } }
      }
      # System stream - Python internals
      else if [logger_name] == "asyncio" or [logger_name] == "PIL" or [logger_name] == "root" {
        mutate { add_field => { "stream" => "system" } }
      }
      
      # ===== APPLICATION STREAM (66 loggers) =====
      # All app loggers go to stream: app with app_module for sub-categorization
      
      # Auth module (13 loggers)
      else if [logger_name] =~ /^apps\.custom_auth/ or [logger_name] =~ /^apps\.onboarding/ {
        mutate { 
          add_field => { 
            "stream" => "app" 
            "app_module" => "auth"
          } 
        }
      }
      
      # Parcels module (4 loggers)
      else if [logger_name] =~ /^apps\.parcels/ {
        mutate { 
          add_field => { 
            "stream" => "app" 
            "app_module" => "parcels"
          } 
        }
      }
      
      # Tenant module (10 loggers)
      else if [logger_name] =~ /^apps\.tenant_manager/ {
        mutate { 
          add_field => { 
            "stream" => "app" 
            "app_module" => "tenant"
          } 
        }
      }
      
      # Notification module (4 loggers)
      else if [logger_name] =~ /^apps\.notification/ {
        mutate { 
          add_field => { 
            "stream" => "app" 
            "app_module" => "notification"
          } 
        }
      }
      
      # Reports module (3 loggers)
      else if [logger_name] =~ /^apps\.manage_reports/ {
        mutate { 
          add_field => { 
            "stream" => "app" 
            "app_module" => "reports"
          } 
        }
      }
      
      # Integrations module (3 loggers)
      else if [logger_name] =~ /^apps\.integrations/ {
        mutate { 
          add_field => { 
            "stream" => "app" 
            "app_module" => "integrations"
          } 
        }
      }
      
      # Dashboard module (4 loggers)
      else if [logger_name] =~ /^apps\.dashboard/ {
        mutate { 
          add_field => { 
            "stream" => "app" 
            "app_module" => "dashboard"
          } 
        }
      }
      
      # Data Governance module (3 loggers)
      else if [logger_name] =~ /^apps\.data_governance/ {
        mutate { 
          add_field => { 
            "stream" => "app" 
            "app_module" => "data_governance"
          } 
        }
      }
      
      # Branded module (5 loggers)
      else if [logger_name] =~ /^apps\.branded/ {
        mutate { 
          add_field => { 
            "stream" => "app" 
            "app_module" => "branded"
          } 
        }
      }
      
      # Container module (2 loggers)
      else if [logger_name] =~ /^apps\.container/ {
        mutate { 
          add_field => { 
            "stream" => "app" 
            "app_module" => "container"
          } 
        }
      }
      
      # Harmonization module (1 logger)
      else if [logger_name] =~ /^apps\.harmonization/ {
        mutate { 
          add_field => { 
            "stream" => "app" 
            "app_module" => "harmonization"
          } 
        }
      }
      
      # Logs module (3 loggers)
      else if [logger_name] =~ /^apps\.logs/ {
        mutate { 
          add_field => { 
            "stream" => "app" 
            "app_module" => "logs"
          } 
        }
      }
      
      # Tasks module (4+ loggers)
      else if [logger_name] =~ /^apps\.cron_tasks/ or [logger_name] =~ /^celery/ or [logger_name] =~ /\.tasks$/ {
        mutate { 
          add_field => { 
            "stream" => "app" 
            "app_module" => "tasks"
          } 
        }
      }
      
      # Common module (8 loggers)
      else if [logger_name] =~ /^apps\.common/ {
        mutate { 
          add_field => { 
            "stream" => "app" 
            "app_module" => "common"
          } 
        }
      }
      
      # Config module (3 loggers)
      else if [logger_name] =~ /^config\./ {
        mutate { 
          add_field => { 
            "stream" => "app" 
            "app_module" => "config"
          } 
        }
      }
      
      # Unknown - catch all others
      else {
        mutate { add_field => { "stream" => "unknown" } }
      }
    } 
    else {
      # No logger_name parsed
      mutate { 
        add_field => { 
          "stream" => "unknown" 
          "logger_name" => "unparsed"
        } 
      }
    }

    # Parse timestamp if grok succeeded
    if "_grokparsefailure_pt" not in [tags] and [log_timestamp] {
      date {
        match => ["log_timestamp", "ISO8601", "yyyy-MM-dd'T'HH:mm:ss"]
        target => "@timestamp"
      }
    }
  }
}

output {
  # Existing services - keep as is
  if [service] == "backend-express" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "express-logs-%{+YYYY.MM.dd}"
      user => "logstash_writer"
      password => "${LOGSTASH_WRITER_PASSWORD}"
    }
  } else if [service] == "backend-fastapi" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "fastapi-logs-%{+YYYY.MM.dd}"
      user => "logstash_writer"
      password => "${LOGSTASH_WRITER_PASSWORD}"
    }
  } 
  # PT logs - single index with stream, app_module, logger_name for filtering
  else if [service] == "pt" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "pt-logs-%{+YYYY.MM.dd}"
      user => "logstash_writer"
      password => "${LOGSTASH_WRITER_PASSWORD}"
    }
  }
}
